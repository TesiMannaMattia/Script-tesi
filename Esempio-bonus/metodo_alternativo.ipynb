{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810b4e88",
   "metadata": {},
   "source": [
    "Si estraggano i primi 7200 luoghi più popolari dal sito https://www.atlasobscura.com/places?sort=likes_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a3b38",
   "metadata": {},
   "source": [
    "## Importazione pacchetti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad70a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import warnings \n",
    "from urllib.request import urlopen\n",
    "import time \n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from  tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaf73ca",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4babf7c9",
   "metadata": {},
   "source": [
    "## 1.1 Ottenere tutti i link dei singoli luoghi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe9ed72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [09:06<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "exception=[]   #In questa lista vengono allocati tutti gli errori riscontrati, si fa per capire se ci sono stati degli errori.\n",
    "               #Viene inserito questo perchè lo script è creato in modo da proseguire e non bloccarsi agli errori, tuttavia bisogna\n",
    "               #tener conto degli errori per capire se lo script è corretto o no.\n",
    "\n",
    "\n",
    "#Dal momento che il link della pagina contiene degli indici si può iterare sugli indici ed utilizzare il metodo get\n",
    "for i in tqdm(range(1,401)):\n",
    "    url='https://www.atlasobscura.com/places?page='+str(i)+'&sort=likes_count' #Muoversi alla pagina successiva\n",
    "    risposta=requests.get(url)                                                 #Prendere l'http        \n",
    "    testo=BeautifulSoup(risposta.text,'html.parser')                           #Formattare l'html\n",
    "    \n",
    "    try:\n",
    "        first_div=testo.find_all(\"div\",{\"class\":\"row vue-js-bte-place-parent js-vue-component-wrap\"}) #find the tag\n",
    "        \n",
    "        \n",
    "        for j in range(0,len(first_div)):\n",
    "            try:\n",
    "                second_div=first_div[j].find_all(\"div\",{\"class\":\"col-md-4 col-sm-6 col-xs-12\"})\n",
    "    \n",
    "                for k in range(0,len(second_div)):\n",
    "                    try:\n",
    "                        a=second_div[k].find(\"a\").get(\"href\").strip()    #Estrarre il link della pagina\n",
    "                     \n",
    "                        with open('links.txt',\"a\")as f:\n",
    "                            f.write(\"https://www.atlasobscura.com\"+str(a))  #Scrivere su un file txt i link\n",
    "                            f.write('\\n')\n",
    "                    except:\n",
    "                        exception.append([i,j,k,risposta])      \n",
    "            except:\n",
    "                exception.append([i,j,None,risposta])   \n",
    "    except:\n",
    "        exception.append([i,None,None,risposta])\n",
    "        \n",
    "    \n",
    "    time.sleep(1) #Per evitare gli errori di tipo \"429 Too Many Requests\"\n",
    "       \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6668440",
   "metadata": {},
   "source": [
    "## 1.2 Estrarre tutti gli html dei singoli luoghi\n",
    "Per ogni singolo link nel txt creato nel paragrafo precedente se ne estrare l'html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "623e22b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7200/7200 [2:18:44<00:00,  1.16s/it]  \n"
     ]
    }
   ],
   "source": [
    "file = open('links.txt')\n",
    "content = file.readlines()\n",
    "for i in tqdm(range(0,len(content))):\n",
    "    url=content[i].strip()    \n",
    "    risposta=requests.get(url)                                               \n",
    "    with open('HTML/html'+str(i)+'.txt',\"a\")as f:\n",
    "        f.write(risposta.text)  #Scrivere ogni singolo HTML su un file txt \n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5e4154",
   "metadata": {},
   "source": [
    "## 1.3 Estrazione dati dagli HTML\n",
    "Per prima cosa si definisce una funzione per estrarre i dati da ogni singolo HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db8a8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estrazione(testo):  \n",
    "    errors=[]\n",
    "    #1 Place Name (to save as placeName): String.\n",
    "    try:\n",
    "        placeName=testo.find(\"h1\",{\"class\":\"DDPage__header-title\"}).text.strip()\n",
    "    except:\n",
    "        placeName=\" \"\n",
    "        errors.append(1)\n",
    "    #---#\n",
    "    #2 Place Tags (to save as placeTags): List of Strings.\n",
    "    try:\n",
    "        placeTags=[]\n",
    "        ff2=testo.find(\"div\",{\"class\":\"item-tags col-xs-12\"})\n",
    "        ff2=ff2.find_all(\"span\")\n",
    "        for i in range(len(ff2)):\n",
    "            placeTags.append(ff2[i].find(\"a\").text.strip())\n",
    "    except:\n",
    "        placeTags=[\" \"]\n",
    "        errors.append(2)\n",
    "\n",
    "\n",
    "\n",
    "    #---#\n",
    "    conta=testo.find_all(\"div\",{\"class\",\"title-md item-action-count\"})\n",
    "\n",
    "    #3 # of people who have been there (to save as numPeopleVisited): Integer.\n",
    "    try:\n",
    "        numPeopleVisited=conta[0].text.strip()\n",
    "    except:\n",
    "        numPeopleVisited=\" \"\n",
    "        errors.append(3)\n",
    "    #---#\n",
    "    #4 # of people who want to visit the place(to save as numPeopleWant): Integer.    \n",
    "    try:\n",
    "        numPeopleWant=conta[1].text.strip()\n",
    "    except:\n",
    "        numPeopleWant=\" \"\n",
    "        errors.append(4)\n",
    "    #---#\n",
    "    #5 Description (to save as placeDesc): String. Everything from under the first image up to \"know before you go\" (orange frame on the example image).\n",
    "    try:\n",
    "        tag=testo.find(\"div\",{\"class\":\"DDP__body-copy\"})\n",
    "        tag=tag.find_all(\"p\")\n",
    "        placeDesc=\"\"\n",
    "        for i in range(0,len(tag)):\n",
    "            placeDesc += str(tag[i].text)\n",
    "    except:\n",
    "        placeDesc=\"\"\n",
    "        errors.append(5)\n",
    "\n",
    "    #6 Short Description (to save as placeShortDesc): String. Everything from the title and location up to the image (blue frame on the example image).\n",
    "    placeShortDesc=\"\"\n",
    "    try:\n",
    "        placeShortDesc2=testo.find(\"h3\", {\"class\",\"DDPage__header-dek\"}).text.strip()\n",
    "    except:\n",
    "        placeShortDesc2=\" \"\n",
    "        errors.append(6.2)\n",
    "    placeShortDesc += placeShortDesc2\n",
    "\n",
    "    #7 Nearby Places (to save as placeNearby): Extract the names of all nearby places, but only keep unique values: List of Strings.\n",
    "    placeNearby=[]\n",
    "    try:\n",
    "        place=testo.find(\"div\",{\"class\":\"DDPageSiderail__column grid-col-lg-4 grid-col-md-5\"})\n",
    "        place=place.find(\"div\",{\"class\":\"DDPageSiderail\"})\n",
    "        place=place.find(\"div\", {\"class\":\"DDPageSiderailRecirc\"})\n",
    "        place=place.find_all(\"a\")\n",
    "        for i in range(0,len(place)):\n",
    "            luogo=place[i].find(\"div\",{\"class\":\"DDPageSiderailRecirc__item-title\"})\n",
    "            placeNearby.append(luogo.text.strip())\n",
    "    except:\n",
    "        placeNearby=[\" \"]\n",
    "        errors.append(7)\n",
    "    #8 Address of the place(to save as placeAddress): String.\n",
    "    try:\n",
    "        placeAddress=testo.find(\"div\",{\"class\":\"DDPageSiderail__column grid-col-lg-4 grid-col-md-5\"})\n",
    "        placeAddress=placeAddress.find(\"div\",{\"class\":\"DDPageSiderail\"})\n",
    "        placeAddress=placeAddress.find(\"aside\", {\"class\":\"DDPageSiderail__details\"})\n",
    "        placeAddress=placeAddress.find(\"address\",{\"class\":\"DDPageSiderail__address\"})\n",
    "        placeAddress=placeAddress.find(\"div\").get_text(\",\").strip().rstrip(',').strip()\n",
    "    except:\n",
    "        placeAddress=\" \"\n",
    "        errors.append(8)\n",
    "\n",
    "    #9 Altitude and Longitude of the place's location(to save as placeAlt and placeLong): Integers\n",
    "    try:\n",
    "        coordinate=testo.find(\"div\",{\"class\":\"DDPageSiderail__column grid-col-lg-4 grid-col-md-5\"})\n",
    "        coordinate=coordinate.find(\"div\",{\"class\":\"DDPageSiderail\"})\n",
    "        coordinate=coordinate.find(\"aside\", {\"class\":\"DDPageSiderail__details\"})\n",
    "        coordinate=coordinate.find(\"div\",{\"class\":\"DDPageSiderail__coordinates js-copy-coordinates\"}).text.strip().split()\n",
    "\n",
    "        placeAlt=float(coordinate[0].replace(\",\",\"\"))\n",
    "        placeLong=float(coordinate[1].replace(\",\",\"\"))\n",
    "    except:\n",
    "        placeAlt=\" \"\n",
    "        placeLong=\" \"\n",
    "        errors.append(9)\n",
    "\n",
    "    #10 The username of the post editors (to save as placeEditors): List of Strings\n",
    "    placeEditors=[]\n",
    "    createdby=[]\n",
    "    Editors=testo.find(\"div\",{\"id\":\"ugc-module\"})\n",
    "    Editors=Editors.find(\"div\",{\"class\":\"DDPContributors\"})\n",
    "    Editors=Editors.find_all(\"div\",{\"class\":\"ugc-editors\"})\n",
    "\n",
    "    try:\n",
    "        for i in range(0,len(Editors)):\n",
    "            tipo=Editors[i].find(\"h6\").text.strip()\n",
    "            if \"edited by\" == tipo.lower():\n",
    "                try:\n",
    "                    g=Editors[i].find(\"div\",{\"class\":\"DDPContributorsList\"})\n",
    "                    g=g.find(\"div\",{\"class\":\"js-editor-list hidden\"})\n",
    "                    g=g.find_all(\"li\")\n",
    "                    for  i in range(0,len(g)):\n",
    "                        a=g[i].find(\"a\").find(\"span\").text.strip()\n",
    "                        placeEditors.append(a)\n",
    "                except:\n",
    "                    placeEditors=[\" \"]\n",
    "                    #errors.append(10.1)\n",
    "                    \n",
    "            elif \"added by\"==tipo.lower():\n",
    "                try:\n",
    "                    creator=Editors[i].find(\"div\",{\"class\":\"DDPContributorsList\"})\n",
    "                    createdby.append(creator.find(\"a\").text)\n",
    "                except:\n",
    "                    createdby=[\" \"]\n",
    "                   # errors.append(10.2)\n",
    "    except:\n",
    "        createdby=[\" \"]\n",
    "        placeEditors=[\" \"] \n",
    "        errors.append(10)\n",
    "    placeEditors=\",\".join(placeEditors)\n",
    "    createdby=\",\".join(createdby)\n",
    "\n",
    "\n",
    "    #11 Post publishing date (to save as placePubDate): datetime.\n",
    "    try:\n",
    "        placePubDate=testo.find(\"div\",{\"id\":\"ugc-module\"})\n",
    "        placePubDate=placePubDate.find(\"div\",{\"class\":\"DDPContributors\"})\n",
    "        placePubDate=placePubDate.find(\"div\",{\"class\":\"DDPContributor__name\"}).text.strip()\n",
    "        placePubDate=datetime.strptime(placePubDate, \"%B %d, %Y\").date() #year, month, day\n",
    "    except:\n",
    "        placePubDate=\" \"\n",
    "        errors.append(11)\n",
    "\n",
    "    #12 The names of the lists that the place was included in (to save as placeRelatedLists): List of Strings.\n",
    "    placeRelatedLists=[]\n",
    "    try:\n",
    "        o=testo.find_all(\"div\",{\"class\":\"card-grid CardRecircSection__card-grid js-inject-gtm-data-in-child-links\"})\n",
    "        o=o[2].find_all(\"div\",{\"class\":\"CardWrapper js-CardWrapper\"})\n",
    "        for i in range(len(o)):\n",
    "            m=o[i].find(\"h3\").text.strip()\n",
    "            placeRelatedLists.append(m)\n",
    "    except:\n",
    "        placeRelatedLists=[\" \"]\n",
    "        errors.append(12)\n",
    "\n",
    "    #13 The names of the related places (to save as placeRelatedPlaces): List of Strings.\n",
    "    placeRelatedPlaces=[]\n",
    "    try:\n",
    "        o=testo.find_all(\"div\",{\"class\":\"card-grid CardRecircSection__card-grid js-inject-gtm-data-in-child-links\"})\n",
    "        o=o[1].find_all(\"div\",{\"class\":\"CardWrapper js-CardWrapper\"})\n",
    "        for i in range(len(o)):\n",
    "            m=o[i].find(\"h3\").text.strip()\n",
    "            placeRelatedPlaces.append(m)\n",
    "    except:\n",
    "        placeRelatedPlaces=[\" \"]\n",
    "        errors.append(13)\n",
    "\n",
    "    #14 The URL of the page of the place (to save as placeURL):String\n",
    "    try:\n",
    "        placeURL=testo.find(\"link\",{\"rel\":\"canonical\"}).get(\"href\")\n",
    "    except:\n",
    "        placeURL=\" \"\n",
    "        errors.append(14)\n",
    "    \n",
    "    \n",
    "\n",
    "    try:\n",
    "        link=testo.find(\"div\",{\"class\":\"DDPage__header-place-location\"})\n",
    "        link=link.find(\"a\").get(\"href\").strip()\n",
    "    except:\n",
    "        link=\" \"\n",
    "       \n",
    "    \n",
    "    d={\"placeName\":placeName,\"placeTags\": \",\".join(placeTags),\"numPeopleVisited\":int(numPeopleVisited),\"numPeopleWant\":int(numPeopleWant),\"placeDesc\":placeDesc,\"placeShortDesc\":placeShortDesc,\n",
    "    \"placeNearby\":\",\".join(placeNearby),\"placeAddress\":placeAddress.strip(),\"placeAlt\":placeAlt,\"placeLong\":placeLong,\"createdby\":createdby,\"placeEditors\":placeEditors,\"placePubDate\":placePubDate,\n",
    "    \"placeRelatedLists\":\",\".join(placeRelatedLists),\"placeRelatedPlaces\":\",\".join(placeRelatedPlaces),\"placeURL\":placeURL}\n",
    "\n",
    "    return  d,errors      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac31621d",
   "metadata": {},
   "source": [
    "## Immagazzinare i dati ottenuti in un file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd5b6d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7200/7200 [22:56<00:00,  5.23it/s]\n"
     ]
    }
   ],
   "source": [
    "anomalie={}\n",
    "for i in tqdm(range(0,7200)):\n",
    "    \n",
    "    with open('HTML/html'+str(i)+'.txt') as f:\n",
    "        testo = f.read()\n",
    "\n",
    "    testo=BeautifulSoup(testo,'html.parser') \n",
    "    d,errori=estrazione(testo)\n",
    "    \n",
    "    if len(errori) != 0:\n",
    "        anomalie[str(i)]=errori\n",
    "    if i==0 :\n",
    "      df=pd.DataFrame(d,index=[i])\n",
    "    else:\n",
    "      dataframe=pd.DataFrame(d,index=[i])\n",
    "      df=df.append(dataframe)\n",
    "        \n",
    "df.to_csv(\"places.csv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792864dd",
   "metadata": {},
   "source": [
    "#### Overview of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0cde089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7200, 17)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"places2.csv\",delimiter=\"\\t\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe89f9",
   "metadata": {},
   "source": [
    "#### Analysis of the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83775f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('anomalie.txt',\"w\")as f:\n",
    "    for i in anomalie.keys():\n",
    "        f.write(i)\n",
    "        f.write(str(anomalie[i]))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in anomalie.keys():\n",
    "    print(anomalie[i],i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6a9f6a",
   "metadata": {},
   "source": [
    "Non ci sono anomalie particolari, sono dovute tutte ad elementi mancanti.  \n",
    "Questo è normale quando si effettua scraping su grandi quantità di dati, ovviamente le pagine non sono tutte uguali.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
